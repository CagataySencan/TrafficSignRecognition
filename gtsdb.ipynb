{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gtsdb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CagataySencan/TrafficSignRecognition/blob/main/gtsdb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Verisetini Kaggle'dan Çekmek İçin Gerekli İşlemler\n"
      ],
      "metadata": {
        "id": "ZWWriT9caIRn"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98NuAK23uXoF"
      },
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfDqNcJruk80"
      },
      "source": [
        "!mkdir ~/.kaggle"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbJzn4dzulUr"
      },
      "source": [
        "!cp /content/kaggle.json ~/.kaggle/kaggle.json"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2r2-IHcLulaR"
      },
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIjrlkSWuydw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61bc076b-3f54-4ab3-fa7b-0d4ea8e7ab5a"
      },
      "source": [
        "! kaggle datasets download safabouguezzi/german-traffic-sign-detection-benchmark-gtsdb"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading german-traffic-sign-detection-benchmark-gtsdb.zip to /content\n",
            "100% 1.61G/1.61G [00:13<00:00, 132MB/s]\n",
            "100% 1.61G/1.61G [00:13<00:00, 126MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfsiZkacu5we"
      },
      "source": [
        "! unzip german-traffic-sign-detection-benchmark-gtsdb.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## YOLO FORMATTING"
      ],
      "metadata": {
        "id": "zjq92bmD7ueZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TXT VE JPGLERİN OLUŞTURULMASI"
      ],
      "metadata": {
        "id": "Jd6zLAfCFU1K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import cv2"
      ],
      "metadata": {
        "id": "3ao8tq0h9Mcj"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Her fotoğraf için annotation txt dosyalarının oluşturulması için ön hazırlık\n",
        "ann = pd.read_csv('/content/gt.txt',\n",
        "                  names=['ImageID',\n",
        "                         'XMin',\n",
        "                         'YMin',\n",
        "                         'XMax',\n",
        "                         'YMax',\n",
        "                         'ClassID'],\n",
        "                  sep=';')\n",
        "\n",
        "# Adding new empty columns to dataFrame to save numbers for YOLO format\n",
        "ann['center x'] = ''\n",
        "ann['center y'] = ''\n",
        "ann['width'] = ''\n",
        "ann['height'] = ''\n",
        "\n",
        "# Calculating bounding box's center in x and y for all rows\n",
        "# Saving results to appropriate columns\n",
        "ann['center x'] = (ann['XMax'] + ann['XMin']) / 2\n",
        "ann['center y'] = (ann['YMax'] + ann['YMin']) / 2\n",
        "\n",
        "# Calculating bounding box's width and height for all rows\n",
        "# Saving results to appropriate columns\n",
        "ann['width'] = ann['XMax'] - ann['XMin']\n",
        "ann['height'] = ann['YMax'] - ann['YMin']\n",
        "\n",
        "# Getting Pandas dataFrame that has only needed columns\n",
        "# By using 'loc' method we locate here all rows but only specified columns\n",
        "# By using copy() we create separate dataFrame not just a reference to the previous one and, in this way, initial dataFrame will not be changed\n",
        "r = ann.loc[:, ['ImageID',\n",
        "                'ClassID',\n",
        "                'center x',\n",
        "                'center y',\n",
        "                'width',\n",
        "                'height']].copy()\n",
        "\n",
        "# Check point\n",
        "# Showing first 5 rows from the dataFrame\n",
        "print(r.head())"
      ],
      "metadata": {
        "id": "aRhBMgzml41M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7376316c-cc27-4aa6-96ee-858f9ca3491d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     ImageID  ClassID  center x  center y  width  height\n",
            "0  00000.ppm       11     794.5     428.5     41      35\n",
            "1  00001.ppm       40    1003.5     410.0     41      44\n",
            "2  00001.ppm       38     414.0     523.0     56      58\n",
            "3  00001.ppm       13    1002.0     362.5     58      55\n",
            "4  00002.ppm       39     949.0     534.0    114     116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''Normalizing YOLO numbers according to the real image width and height\n",
        "Saving annotations in txt files\n",
        "Converting images from ppm to jpg'''\n",
        "\n",
        "def annotation(fullPathtoDataset):\n",
        "  os.chdir(fullPathtoDataset)\n",
        "\n",
        "  for current_dir, dirs, files in os.walk('.'):\n",
        "     for f in files:\n",
        "        if f.endswith('.ppm'):\n",
        "          image_ppm = cv2.imread(f)\n",
        "          h, w = image_ppm.shape[:2]\n",
        "\n",
        "          # Slicing only name of the file without extension\n",
        "          image_name = f[:-4]\n",
        "\n",
        "          sub_r = r.loc[r['ImageID'] == f].copy()\n",
        "\n",
        "          # Normalizing calculated bounding boxes' coordinates according to the real image width and height\n",
        "          sub_r['center x'] = sub_r['center x'] / w\n",
        "          sub_r['center y'] = sub_r['center y'] / h\n",
        "          sub_r['width'] = sub_r['width'] / w\n",
        "          sub_r['height'] = sub_r['height'] / h\n",
        "\n",
        "          resulted_frame = sub_r.loc[:, ['ClassID',\n",
        "                                         'center x',\n",
        "                                         'center y',\n",
        "                                         'width',\n",
        "                                         'height']].copy()\n",
        "\n",
        "          # Checking if there is no any annotations for current image\n",
        "          if resulted_frame.isnull().values.all():\n",
        "              continue\n",
        "\n",
        "          # Preparing path where to save txt file\n",
        "          path_to_save = fullPathtoDataset + '/' + image_name + '.txt'\n",
        "\n",
        "          # Saving resulted Pandas dataFrame into txt file\n",
        "          resulted_frame.to_csv(path_to_save, header=False, index=False, sep=' ')\n",
        "\n",
        "          # Preparing path where to save jpg image\n",
        "          path_to_save = fullPathtoDataset + '/' + image_name + '.jpg'\n",
        "\n",
        "          # Saving image in jpg format by OpenCV function that uses extension to choose format to save with\n",
        "          cv2.imwrite(path_to_save, image_ppm)"
      ],
      "metadata": {
        "id": "kvb7bZuq71os"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "annotation('/content/TestIJCNN2013/TestIJCNN2013Download')"
      ],
      "metadata": {
        "id": "E8aBAqzJA5DS"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "rootdir = '/content/TrainIJCNN2013/TrainIJCNN2013'\n",
        "for path in Path(rootdir).iterdir():\n",
        "  if path.is_dir():\n",
        "    path=str(path)\n",
        "    annotation(path)"
      ],
      "metadata": {
        "id": "mVAjjxOyEC9g"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRAİN VE TEST TXTLERİN OLUŞTURULMASI"
      ],
      "metadata": {
        "id": "v2MRyWY1FdLk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/TestIJCNN2013/TestIJCNN2013Download')\n",
        "p = []\n",
        "for current_dir, dirs, files in os.walk('.'):\n",
        "  # Going through all files\n",
        "  for f in files:\n",
        "    # Checking if filename ends with '.jpg'\n",
        "    if f.endswith('.jpg'):\n",
        "      path_to_save_into_txt_files = '/content/TestIJCNN2013/TestIJCNN2013Download' + '/' + f\n",
        "\n",
        "      # Appending the line into the list\n",
        "      p.append(path_to_save_into_txt_files + '\\n')\n",
        "\n",
        "# Creating file train.txt and writing 85% of lines in it  \n",
        "os.chdir('/content/TestIJCNN2013')\n",
        "with open('test.txt', 'w') as test_txt:\n",
        "  # Going through all elements of the list\n",
        "  for e in p:\n",
        "    # Writing current path at the end of the file\n",
        "    test_txt.write(e)"
      ],
      "metadata": {
        "id": "pnd11paBFknr"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p = []\n",
        "\n",
        "rootdir = '/content/TrainIJCNN2013/TrainIJCNN2013'\n",
        "for path in Path(rootdir).iterdir():\n",
        "  if path.is_dir():\n",
        "    path=str(path)\n",
        "    os.chdir(path)\n",
        "    for current_dir, dirs, files in os.walk('.'):\n",
        "      # Going through all files\n",
        "      for f in files:  \n",
        "        # Checking if filename ends with '.jpg'\n",
        "        if f.endswith('.jpg'): \n",
        "          path_to_save_into_txt_files = path + '/' + f\n",
        "\n",
        "          # Appending the line into the list\n",
        "          p.append(path_to_save_into_txt_files + '\\n')\n",
        "\n",
        "# Creating file train.txt and writing 85% of lines in it  \n",
        "os.chdir('/content/TrainIJCNN2013')\n",
        "with open('train.txt', 'w') as train_txt:\n",
        "  # Going through all elements of the list\n",
        "  for e in p:\n",
        "    # Writing current path at the end of the file\n",
        "    train_txt.write(e)"
      ],
      "metadata": {
        "id": "51OSuUb9J1dZ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CLASSES.NAMES VE DATA.DATA"
      ],
      "metadata": {
        "id": "QzurqDRfNIrb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classes = { 0:'Hız Limiti (20km/s)',\n",
        "            1:'Hız Limiti (30km/s)', \n",
        "            2:'Hız Limiti (50km/s)', \n",
        "            3:'Hız Limiti (60km/s)', \n",
        "            4:'Hız Limiti (70km/s)', \n",
        "            5:'Hız Limiti (80km/s)', \n",
        "            6:'Hız Limitinin bitişi (80km/s)', \n",
        "            7:'Hız Limiti (100km/s)', \n",
        "            8:'Hız Limiti (120km/s)', \n",
        "            9:'Geçiş yok', \n",
        "            10:'Ağırlığı 3.5 ton üstü olan araçlar geçemez', \n",
        "            11:'Kavşakta geçiş hakkı', \n",
        "            12:'Öncelikli yol', \n",
        "            13:'Yol ver', \n",
        "            14:'Dur', \n",
        "            15:'Araç giremez', \n",
        "            16:'3.5 Ton üzeri araçlar yasak', \n",
        "            17:'Giriş yok', \n",
        "            18:'Genel uyarı', \n",
        "            19:'Sola tehlikeli viraj', \n",
        "            20:'Sağa tehlikeli viraj', \n",
        "            21:'Sağa tehlikeli devamlı virajlar', \n",
        "            22:'Engebeli yol', \n",
        "            23:'Kaygan yol', \n",
        "            24:'Sağdan daralan yol', \n",
        "            25:'Yol çalışması', \n",
        "            26:'Trafik işaretleri', \n",
        "            27:'Yaya geçidi', \n",
        "            28:'Okul geçidi', \n",
        "            29:'Bisiklet yolu', \n",
        "            30:'Buzlanmaya dikkat',\n",
        "            31:'Vahşi hayvan çıkabilir', \n",
        "            32:'Hız sınırı sonu', \n",
        "            33:'Sadece sağa dönüş var', \n",
        "            34:'Sadece sola dönüş var', \n",
        "            35:'Dönüş yok', \n",
        "            36:'Sola dönüş yok', \n",
        "            37:'Sağa dönüş yok', \n",
        "            38:'Sağdan gidin', \n",
        "            39:'Soldan gidin', \n",
        "            40:'Dönüş önceliği', \n",
        "            41:'Geçiş olmayan yolun sonu', \n",
        "            42:'3.5 Ton üzeri araçlar girebilir' }\n",
        "\n",
        "c = pd.DataFrame([classes])\n",
        "c.to_csv('/content/classes.names', header=False, index=False, sep='\\n')"
      ],
      "metadata": {
        "id": "B8RyaXHrNNa7"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CUSTOM_DATA.DATA FILE\n",
        "\n",
        "with open('/content/ts_data.data', 'w+') as out:\n",
        "  out.write('classes = 43\\n')\n",
        "  out.write('train = /content/TrainIJCNN2013/train.txt\\n')\n",
        "  out.write('valid = /content/TestIJCNN2013/test.txt\\n')\n",
        "  out.write('names = /content/classes.names\\n')\n",
        "  out.write('backup = backup')\n",
        "\n",
        "out.close()"
      ],
      "metadata": {
        "id": "7wqwTJ_VNd2V"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Darknet\n"
      ],
      "metadata": {
        "id": "NtGPjreVaQP9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd '/content'\n",
        "!git clone https://github.com/AlexeyAB/darknet/\n",
        "!cd '/darknet'\n",
        "!make"
      ],
      "metadata": {
        "id": "-gJn7IWFY1cY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!make"
      ],
      "metadata": {
        "id": "O_ztXSr0hLtp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}